{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utils\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/cleaned_combined_gender.csv'\n",
    "MODELS_PATH = 'models/diabetes/'\n",
    "RESULTS_PATH = 'results/diabetes/'\n",
    "os.makedirs(MODELS_PATH, exist_ok = True)\n",
    "os.makedirs(RESULTS_PATH, exist_ok = True)\n",
    "\n",
    "vars = pd.read_csv('variables.csv')\n",
    "cat_cols = vars[vars['Variable Type'].fillna('-').str.contains('Cat')]['Variable Common Name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df = df[df['Has diabetes'].isin([1, 2])] # Keep only those with 'Has diabtes' in [1, 2] (Yes / No)\n",
    "df = df.dropna(subset=['Has diabetes']) # y cannot have any missing values\n",
    "assert df.isna().sum().sum() == 0\n",
    "\n",
    "X = df.drop(columns=['Has diabetes'])\n",
    "y = (df['Has diabetes'] == 1).astype('category')\n",
    "\n",
    "cat_cols = [col for col in cat_cols if col in X.columns]\n",
    "num_cols = [col for col in X.columns if col not in cat_cols]\n",
    "\n",
    "X = pd.get_dummies(X, columns = cat_cols, drop_first = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_sel_from_model = lambda model, param_grid: GridSearchCV(\n",
    "\n",
    "    make_pipeline(\n",
    "        # Standardize numerical features\n",
    "        ColumnTransformer(transformers = [('num', StandardScaler(), num_cols)], remainder = 'passthrough'),\n",
    "        SelectFromModel(RandomForestClassifier(n_jobs = -1, random_state = 42)), # select most important features\n",
    "        model\n",
    "    ),\n",
    "\n",
    "    # Search for the best no. of features to select and model hyperparameters\n",
    "    param_grid = param_grid,\n",
    "\n",
    "    # Use 5-fold cross validation\n",
    "    cv = 5,\n",
    "\n",
    "    # Refit the model with the best parameters on all the data\n",
    "    # (will be stored in the best_estimator_ attribute)\n",
    "    refit = True,\n",
    "\n",
    "    # Use area under roc curve to evaluate best params\n",
    "    scoring = 'roc_auc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = (np.arange(0.25, 1.25, 0.25) * X_train.shape[1]).astype(int).tolist()\n",
    "model_and_params = [\n",
    "    (\n",
    "        DummyClassifier(strategy = 'most_frequent'),\n",
    "        {\n",
    "            'selectfrommodel__max_features': max_features,\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        DecisionTreeClassifier(random_state = 42),\n",
    "        {\n",
    "            'selectfrommodel__max_features': max_features,\n",
    "            'decisiontreeclassifier__max_depth': [None, 10, 100],\n",
    "            'decisiontreeclassifier__min_samples_split': [2, 4],\n",
    "            'decisiontreeclassifier__min_samples_leaf': [1, 2],\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        RandomForestClassifier(n_jobs = -1, random_state = 42),\n",
    "        {\n",
    "            'selectfrommodel__max_features': max_features,\n",
    "            'randomforestclassifier__n_estimators': [100, 500, 1000, 2000],\n",
    "            'randomforestclassifier__max_depth': [None, 10, 100],\n",
    "            'randomforestclassifier__min_samples_split': [2, 4],\n",
    "            'randomforestclassifier__min_samples_leaf': [1, 2],\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        LogisticRegression(max_iter = 1000, random_state = 42),\n",
    "        {\n",
    "            'selectfrommodel__max_features': max_features,\n",
    "            'logisticregression__C': [0.1, 0.5, 1, 10],\n",
    "            'logisticregression__class_weight': [None, 'balanced']\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        KNeighborsClassifier(),\n",
    "        {\n",
    "            'selectfrommodel__max_features': max_features,\n",
    "            'kneighborsclassifier__n_neighbors': [1, 3, 5, 10, 50, 100, 200],\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        LinearDiscriminantAnalysis(),\n",
    "        {\n",
    "            'selectfrommodel__max_features': max_features,\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        QuadraticDiscriminantAnalysis(),\n",
    "        {\n",
    "            'selectfrommodel__max_features': max_features,\n",
    "        }\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier ...\n",
      "Best params: {'selectfrommodel__max_features': 30}\n",
      "DecisionTreeClassifier ...\n",
      "Best params: {'decisiontreeclassifier__max_depth': 10, 'decisiontreeclassifier__min_samples_leaf': 2, 'decisiontreeclassifier__min_samples_split': 2, 'selectfrommodel__max_features': 30}\n",
      "RandomForestClassifier ...\n",
      "Best params: {'randomforestclassifier__max_depth': None, 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 2000, 'selectfrommodel__max_features': 30}\n",
      "LogisticRegression ...\n",
      "Best params: {'logisticregression__C': 0.1, 'logisticregression__class_weight': None, 'selectfrommodel__max_features': 30}\n",
      "KNeighborsClassifier ...\n",
      "Best params: {'kneighborsclassifier__n_neighbors': 100, 'selectfrommodel__max_features': 30}\n",
      "LinearDiscriminantAnalysis ...\n",
      "Best params: {'selectfrommodel__max_features': 30}\n",
      "QuadraticDiscriminantAnalysis ...\n",
      "Best params: {'selectfrommodel__max_features': 30}\n"
     ]
    }
   ],
   "source": [
    "for model, param_grid in model_and_params:\n",
    "\n",
    "    print(f'{model.__class__.__name__} ...')\n",
    "\n",
    "    p = pipe_sel_from_model(model, param_grid)\n",
    "    p.fit(X_train, y_train)\n",
    "    print('Best params:', p.best_params_)\n",
    "\n",
    "    # Save the GridSearchCV object\n",
    "    with open(os.path.join(MODELS_PATH, f'{model.__class__.__name__}.pkl'), 'wb') as f:\n",
    "        pickle.dump(p, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best CV Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>No. of selected vars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.937946</td>\n",
       "      <td>0.864248</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.939369</td>\n",
       "      <td>0.841802</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.943573</td>\n",
       "      <td>0.823144</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.807653</td>\n",
       "      <td>0.817619</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.899923</td>\n",
       "      <td>0.792907</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.926003</td>\n",
       "      <td>0.629665</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Best CV Score  Test Score  \\\n",
       "2             LogisticRegression       0.937946    0.864248   \n",
       "5     LinearDiscriminantAnalysis       0.939369    0.841802   \n",
       "3         RandomForestClassifier       0.943573    0.823144   \n",
       "4         DecisionTreeClassifier       0.807653    0.817619   \n",
       "6  QuadraticDiscriminantAnalysis       0.899923    0.792907   \n",
       "0           KNeighborsClassifier       0.926003    0.629665   \n",
       "1                DummyClassifier       0.500000    0.500000   \n",
       "\n",
       "   No. of selected vars  \n",
       "2                    20  \n",
       "5                    20  \n",
       "3                    20  \n",
       "4                    20  \n",
       "6                    20  \n",
       "0                    20  \n",
       "1                    20  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model_name in os.listdir(MODELS_PATH):\n",
    "\n",
    "    # Load the GridSearchCV object\n",
    "    with open(os.path.join(MODELS_PATH, model_name), 'rb') as f:\n",
    "        grid_cv = pickle.load(f)\n",
    "\n",
    "    # Columns selected by the SelectFromModel\n",
    "    selected_cols = [c for c, s in zip(X_train.columns, grid_cv.best_estimator_[1].get_support()) if s]\n",
    "    \n",
    "    # Get the best score and parameters\n",
    "    best_cv_score = grid_cv.best_score_\n",
    "    best_params = grid_cv.best_params_\n",
    "    preds = grid_cv.best_estimator_[-1].predict(StandardScaler().fit_transform(X_test[selected_cols]))\n",
    "    test_score = roc_auc_score(y_test, preds)\n",
    "    selected_features = grid_cv.best_estimator_.named_steps['selectfrommodel'].get_support().sum()\n",
    "\n",
    "    results.append((model_name.split('.')[0], best_cv_score, test_score, selected_features))\n",
    "\n",
    "results = pd.DataFrame(results, columns = ['Model', 'Best CV Score', 'Test Score', 'No. of selected vars']).sort_values('Test Score', ascending = False)\n",
    "results.to_csv(os.path.join(RESULTS_PATH, 'results_diabetes.csv'), index = False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>15</th>\n",
       "      <th>11</th>\n",
       "      <th>7</th>\n",
       "      <th>5</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <td>Glycohemoglobin (%)  (AIC)</td>\n",
       "      <td>Close relative had diabetes?_2.0</td>\n",
       "      <td>Age in years</td>\n",
       "      <td>Total Cholesterol (mg/dL)</td>\n",
       "      <td>Hip Circumference (cm)</td>\n",
       "      <td>Waist Circumference (cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coef</th>\n",
       "      <td>1.549278</td>\n",
       "      <td>-0.867314</td>\n",
       "      <td>0.674884</td>\n",
       "      <td>-0.480543</td>\n",
       "      <td>-0.440967</td>\n",
       "      <td>0.41718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0                                 15  \\\n",
       "Feature  Glycohemoglobin (%)  (AIC)  Close relative had diabetes?_2.0   \n",
       "Coef                       1.549278                         -0.867314   \n",
       "\n",
       "                   11                         7                       5   \\\n",
       "Feature  Age in years  Total Cholesterol (mg/dL)  Hip Circumference (cm)   \n",
       "Coef         0.674884                  -0.480543               -0.440967   \n",
       "\n",
       "                               3   \n",
       "Feature  Waist Circumference (cm)  \n",
       "Coef                      0.41718  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the logistic's GridSearchCV object\n",
    "with open(os.path.join(MODELS_PATH, 'LogisticRegression.pkl'), 'rb') as f:\n",
    "    grid_cv = pickle.load(f)\n",
    "\n",
    "# Columns selected by the SelectFromModel\n",
    "selected_cols = [c for c, s in zip(X_train.columns, grid_cv.best_estimator_[1].get_support()) if s]\n",
    "\n",
    "# Show coefs\n",
    "coefs = pd.DataFrame({\n",
    "    'Feature': selected_cols,\n",
    "    'Coef': grid_cv.best_estimator_[-1].coef_[0]\n",
    "})\n",
    "coefs['Abs Coef'] = np.abs(coefs['Coef'])\n",
    "\n",
    "to_report = coefs.sort_values('Abs Coef', ascending = False).drop(columns = ['Abs Coef']).head(6).T\n",
    "to_report.to_csv(os.path.join(RESULTS_PATH, 'coefs_diabetes.csv'), index = False)\n",
    "to_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
